---
title: "PEM LiDAR Downloads"
author: "C Armour"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}

require(sf)
require(tidyverse)
require(pbapply)
require(future)
require(parallel)
require(arcgisbinding)
require(lidR)
require(future)
require(terra)
require(magrittr)

terra::terraOptions(overwrite = T, todisk = T, tempdir = "E:/temp")

## Write simple function to source all other functions so we can refresh with a simple function call
source_functions <- function(){
  list.files(str_c(getwd(), "/functions"), pattern = ".R$", full.names = T) %>% lapply(source)
}

source_functions()
```

First, set up your working folder on drive/server that contains at least 100GB - i.e., NOT the working directory for the package. For example, our working folder is named `D:/Kitimat_LiDAR/`. The `setup_folders` function will take care of the rest.

The `data` folder in the top branch will contain all your downloaded ALS data and derivatives. The `data.path` variable is read into nearly everything - the functions will yell at you if it is not there.

The `AOI` folder in the top branch will need to contain your area of interest, so dump it in there. If your AOI is a KMZ, you can use the function `kmz_to_gpkg` to unzip, convert to a geopackage, and write it to the `AOI` folder, returning the geopackage path. This function also automatically transforms the KMZ file GCS from latitude/longitude to EPSG:3005 (NAD 83 / BC Albers).

```{r setup-folder-structure, include = FALSE}

data.path <- str_c("D:/Kitimat_LiDAR/data_test/")
aoi.path <- str_replace(data.path, pattern = "data_test", replacement = "AOI")
setup_folders(data.path)

## Use for KMZ - read your KMZ file path in
# kmz.path <- "D:/Kitimat_LiDAR/AOI/Kitamat PEM AOI - general.kmz"
# kmz_to_gpkg(aoi.path, kmz.path = kmz.path) %>% sf::st_read()
# rm(kmz.path)

## Already have a geopackage or shapefile? Dump it in your AOI folder and put the path here
aoi <- sf::st_read("D:/Kitimat_LiDAR/AOI/AOI.gpkg")

```

At least once every six months, the index of available LiDAR files
should be re-downloaded from the portal. The code chunk below will check
the date of the most recent index and download a newer version if
applicable and an ArcGIS license is available. It returns the file path
of the relevant geopackage after this operation.

If you need to update manually for some reason, the instructions to do
this are as follows:

1.  Navigate to LidarBC Map Grid
    <https://governmentofbc.maps.arcgis.com/home/item.html?id=5f6a1f31212a4cb2826743d2e52ef02a>
2.  Select `Open in ArcGIS Desktop` -\> `Open in ArcGIS Pro`
3.   Double click `item.pitemx` file to open in ArcGIS. This is also
    stored in the `las_index_files` folder.
4.  Download point cloud index layer (eg
    `Point Cloud Index - 1:2,500 Grid`)
5.  Use "`Export Features`" tool and save to the `las_index_files`
    folder using the following format: "`las_index_YYYY-MM-DD.shp`"
6.  Read this shapefile in as your index. Optional: export as `.gpkg`.

```{r get-layers}

## Pull the AOI index
index <- make_gpkg_index() %>% st_read()

```

Here, we query the LiDAR data to create an index of tiles to be
downloaded. The `data.path` should already be specified in the global
environment but is named here as an argument for easier troubleshooting.
This function returns a standard dataframe. You can use the
`keep.geometry = TRUE` argument to retain the spatial features of the
tile index. This is useful if you want to view the tile coverage, but it
is dropped by default as it slows the download process. For similar purposes, you can choose to keep index tiles that are already downloaded using the keep.existing argument

```{r query-tiles, echo = FALSE}

aoi.index <- query_lidarbc(data.path = data.path, aoi = aoi, index = index, keep.existing = FALSE)

```

Next is the download of the tiles. The following chunk takes the table
outputted from the `get-layers` chunk and parallelizes it for faster
download. You can set the number of cores in the `cores` variable, which defaults to 6.

After the tiles are downloaded, they need to be checked to ensure they coordinate systems are consistent. This is done using the LAScatalog engine in the `lidR` package, and depending on the number of downloaded tiles, typically takes hours to days to complete. A progress bar will appear with this function giving you the approximate time.

```{r download}

download_lidarbc(aoi.index = aoi.index, data.path = data.path, cores = 6L)

retile_lidarbc(data.path = data.path, cores = 6L)
normalize_lidarbc(data.path = data.path, cores = 6L)

create_DEM(data.path = data.path, output.res = c(5, 10, 20), cores = 6L)

```



